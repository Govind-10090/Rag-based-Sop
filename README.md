# Policy Ingestion and Retrieval Engine

This project implements a Retrieval-Augmented Generation (RAG) system for querying policy documents.

## ğŸ“ Directory Structure
```
policy-ingestion-pipeline/
â”œâ”€â”€ src/              # Source code (ingestion & retrieval)
â”œâ”€â”€ app/              # CLI Application
â”œâ”€â”€ data/             # Data storage (raw PDFs)
â”œâ”€â”€ vectorstore/      # Persisted FAISS index
â”œâ”€â”€ libs/             # Local libraries (custom fix for environment)
â””â”€â”€ TROUBLESHOOTING.md
```

## ğŸš€ Quick Start (Fresh Run)

If you have closed everything, follow these exact steps:

### Step 1: Start Database (Ollama)
Open a **new, separate terminal window** and run:
```powershell
& "C:\Users\Asus\AppData\Local\Programs\Ollama\ollama.exe" serve
```
*(Keep this window open. It acts as the database server.)*

### Step 2: Run Chat App
Open your **main terminal** (inside this folder) and run:
```powershell
python app/cli.py
```

---

## âš™ï¸ Setup (First Time Only)
If you haven't processed the PDF yet (or want to reset):
```powershell
python src/ingestion/run_ingestion.py
```

## ğŸ›  Features
-   **Ingestion (Week 1)**: Robust PDF loaders & standard chunks.
-   **Retrieval (Week 2)**: Strict guardrails against hallucination.
-   **Local Dependencies**: Uses `libs/` to avoid Python version conflicts.

## â“ Troubleshooting
-   **Ollama Error**: If connection fails, ensure Step 1 is running.
-   **Imports Error**: If you see "ModuleNotFoundError", ensure you are running python from the project root so it finds `libs/`.
